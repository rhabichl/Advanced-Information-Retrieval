\documentclass[12pt,a4paper]{article}

% ----- PACKAGES -----
\usepackage[utf8]{inputenc}
\usepackage{graphicx}
\usepackage{geometry}
\usepackage{setspace}
\usepackage{hyperref}
\usepackage{fancyhdr}
\usepackage{titlesec}
\usepackage[maxbibnames=3,minbibnames=1,maxcitenames=2,mincitenames=1,style=numeric-comp,backend=biber]{biblatex}
\addbibresource{references.bib}


\geometry{margin=1in}
\setstretch{1.2}
\pagestyle{fancy}
\fancyhf{}
\rhead{Project Design Document}
\lhead{\leftmark}
\rfoot{Page \thepage}

\title{
    \vspace{-2cm}
    \textbf{Advanced Information Retrieval}\\[0.2cm]
    \large Fine-Tuning and Transferability in Legal Information Retrieval\\[0.2cm]
    \normalsize Group Number: 27\\[0.3cm]
}
\author{
    Raphael Habichler\thanks{student-id: 12419578, Role: Data Processing \& Fine-tuning} \and
    Mark Sesko\thanks{student-id: 12114879, Role: Evaluation \& Analysis} \and
    Paul Brandst√§tter\thanks{student-id: 12212566, Role: Dataset Preparation \& Documentation}
}
\date{\today}

\titleformat{\section}{\large\bfseries}{\thesection}{1em}{}
\titleformat{\subsection}{\normalsize\bfseries}{\thesubsection}{1em}{}

\begin{document}
\maketitle

\section{Abstract}
This project investigates the transferability of domain-specific fine-tuned embedding models across different legal jurisdictions. We fine-tune the Qwen3-Embedding-8B model on German legal data and evaluate its performance on Austrian, German, and Chinese legal corpora to assess cross-jurisdictional knowledge transfer.

\section{Idea and Goal}
Research Question: Can a legal embedding model fine-tuned on German law effectively retrieve relevant documents in other jurisdictions (Austrian and Chinese law)?

The goal is to build legal information retrieval systems that work across multiple jurisdictions without requiring extensive training data for each legal system. This addresses the challenge of cross-jurisdictional legal search and comparative law analysis.

\section{Main Task}
Our focus is on fine-tuning a state-of-the-art embedding model (Qwen3-Embedding-8B \cite{qwen3embedding}) on German legal data and measuring how well this domain-specific knowledge transfers to other legal systems, specifically Austrian and Chinese law.

\section{Dataset and Processing}
\subsection{Data Sources}
We use three legal datasets from different jurisdictions. 
The Austrian Law Data is a synthetic dataset created from Austrian legal documents. Since no pre-labeled query-document pairs exist, we generate queries using LLMs to create evaluation pairs. 
The German Law Data consists of the GerDaLIR dataset \cite{wrzalik-krechel-2021-gerdalir} and German legal corpus \cite{9723721} with pre-labeled query-document pairs for fine-tuning and evaluation. 
The Chinese Law Data uses the LeCaRDv2 dataset \cite{li2023lecardv2} with existing query-document annotations.

\subsection{Processing}
Data preprocessing includes text normalization, document segmentation, and query-document pair preparation. 
For Austrian data, we synthetically generate queries from legal documents to create the evaluation dataset.

\section{Methods and Models}
We use the Qwen3-Embedding-8B model \cite{qwen3embedding} and compare two experimental conditions. 
The baseline uses the pre-trained Qwen3-Embedding-8B evaluated directly on all three jurisdictions. 
The fine-tuned approach adapts the model specifically on the German domain-specific dataset, then evaluates it on all three jurisdictions to assess transfer learning.

\subsection{Fine-tuning Process}
The fine-tuning procedure adapts the pre-trained model to the legal domain using German legal query-document pairs from the GerDaLIR dataset. 
We employ a cosine similarity loss function that maximizes similarity between relevant query-document pairs and minimizes similarity for irrelevant pairs. 
Both queries and documents are independently encoded through the embedding model, then pooled to create fixed-size vector representations. 
The objective is to learn embeddings where semantically related legal texts are closer in vector space. 
This domain-adapted model is then tested on Austrian (synthetic) and Chinese legal data to measure how well legal knowledge transfers across jurisdictions and languages.

\section{Evaluation}
We measure retrieval performance using standard information retrieval metrics. 
Precision@k measures the proportion of relevant documents in the top-k results. 
Recall@k captures the proportion of all relevant documents found in the top-k results. 
nDCG@k (Normalized Discounted Cumulative Gain) accounts for ranking quality by giving higher weight to correctly ranked relevant documents. 
Performance is compared between the baseline and fine-tuned models across all three jurisdictions to quantify transferability.

\section{Workflow}
Figure~\ref{fig:flowchart} illustrates our complete research pipeline from data collection through evaluation.

\begin{figure}[h]
\centering
\includegraphics[width=\textwidth]{flowchart.pdf}
\caption{Project workflow and methodology}
\label{fig:flowchart}
\end{figure}

\newpage
\printbibliography 
\end{document}
